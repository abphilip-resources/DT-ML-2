{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0849ee1",
   "metadata": {
    "papermill": {
     "duration": 0.006092,
     "end_time": "2023-03-17T04:16:39.381899",
     "exception": false,
     "start_time": "2023-03-17T04:16:39.375807",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**This notebook is an exercise in the [Intro to Game AI and Reinforcement Learning](https://www.kaggle.com/learn/intro-to-game-ai-and-reinforcement-learning) course.  You can reference the tutorial at [this link](https://www.kaggle.com/alexisbcook/n-step-lookahead).**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e59996",
   "metadata": {
    "papermill": {
     "duration": 0.005899,
     "end_time": "2023-03-17T04:16:39.392952",
     "exception": false,
     "start_time": "2023-03-17T04:16:39.387053",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "\n",
    "In the tutorial, you learned how to build a reasonably intelligent agent with the minimax algorithm.  In this exercise, you will check your understanding and submit your own agent to the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bef2d3c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T04:16:39.406358Z",
     "iopub.status.busy": "2023-03-17T04:16:39.405785Z",
     "iopub.status.idle": "2023-03-17T04:16:39.464594Z",
     "shell.execute_reply": "2023-03-17T04:16:39.463218Z"
    },
    "papermill": {
     "duration": 0.069152,
     "end_time": "2023-03-17T04:16:39.467772",
     "exception": false,
     "start_time": "2023-03-17T04:16:39.398620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.game_ai.ex3 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4e4024",
   "metadata": {
    "papermill": {
     "duration": 0.004818,
     "end_time": "2023-03-17T04:16:39.477828",
     "exception": false,
     "start_time": "2023-03-17T04:16:39.473010",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1) A closer look\n",
    "\n",
    "The heuristic from the tutorial looks at all groups of four adjacent grid locations on the same row, column, or diagonal and assigns points for each occurrence of the following patterns:\n",
    "\n",
    "<center>\n",
    "<img src=\"https://i.imgur.com/3NvBEGL.png\" width=70%><br/>\n",
    "</center>\n",
    "\n",
    "Is it really necessary to use so many numbers to define the heuristic?  Consider simplifying it, as in the image below.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://i.imgur.com/grViegG.png\" width=70%><br/>\n",
    "</center>\n",
    "\n",
    "How would each heuristic score the potential moves in the example below (where, in this case, the agent looks only one step ahead)?  Which heuristic would lead to the agent selecting the better move?\n",
    "\n",
    "<center>\n",
    "<img src=\"https://i.imgur.com/LWPLy7N.png\" width=100%><br/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d14466ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T04:16:39.489773Z",
     "iopub.status.busy": "2023-03-17T04:16:39.489344Z",
     "iopub.status.idle": "2023-03-17T04:16:39.495179Z",
     "shell.execute_reply": "2023-03-17T04:16:39.493732Z"
    },
    "papermill": {
     "duration": 0.014901,
     "end_time": "2023-03-17T04:16:39.497792",
     "exception": false,
     "start_time": "2023-03-17T04:16:39.482891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# q_1.hint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "712d21de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T04:16:39.511019Z",
     "iopub.status.busy": "2023-03-17T04:16:39.510109Z",
     "iopub.status.idle": "2023-03-17T04:16:39.522191Z",
     "shell.execute_reply": "2023-03-17T04:16:39.520827Z"
    },
    "papermill": {
     "duration": 0.021401,
     "end_time": "2023-03-17T04:16:39.524807",
     "exception": false,
     "start_time": "2023-03-17T04:16:39.503406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 4, \"questionId\": \"1_WorseHeuristic\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc99\">Solution:</span> The first heuristic is guaranteed to select column 2 to block the opponent from winning.  The second heuristic selects either column 2 or column 3 (where it selects each with 50% probability). Thus, for this game board, the first heuristic is better. In general, we can expect that the first heuristic is a better heuristic, since we cannot trust the second heuristic to block the opponent from winning."
      ],
      "text/plain": [
       "Solution: The first heuristic is guaranteed to select column 2 to block the opponent from winning.  The second heuristic selects either column 2 or column 3 (where it selects each with 50% probability). Thus, for this game board, the first heuristic is better. In general, we can expect that the first heuristic is a better heuristic, since we cannot trust the second heuristic to block the opponent from winning."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check your answer (Run this code cell to receive credit!)\n",
    "q_1.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387c709f",
   "metadata": {
    "papermill": {
     "duration": 0.005188,
     "end_time": "2023-03-17T04:16:39.535896",
     "exception": false,
     "start_time": "2023-03-17T04:16:39.530708",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2) Count the leaves\n",
    "\n",
    "In the tutorial, we worked with a small game tree.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://i.imgur.com/BrRe7Bu.png\" width=90%><br/>\n",
    "</center>\n",
    "\n",
    "The game tree above has 8 leaf nodes that appear at the bottom of the tree.  By definition, \"leaf nodes\" in a game tree are nodes that don't have nodes below them.\n",
    "\n",
    "In the ConnectX competition, the game trees will be much larger!  \n",
    "\n",
    "To see this, consider a minimax agent that is trying to plan its first move, where all columns in the game board are  empty.  Say the agent builds a game tree of depth 3.  How many leaf nodes are in the game tree?  \n",
    "\n",
    "Use your answer to fill in the blank below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dd2b4ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T04:16:39.550103Z",
     "iopub.status.busy": "2023-03-17T04:16:39.549392Z",
     "iopub.status.idle": "2023-03-17T04:16:39.559934Z",
     "shell.execute_reply": "2023-03-17T04:16:39.558685Z"
    },
    "papermill": {
     "duration": 0.020669,
     "end_time": "2023-03-17T04:16:39.562721",
     "exception": false,
     "start_time": "2023-03-17T04:16:39.542052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.2, \"interactionType\": 1, \"questionType\": 1, \"questionId\": \"2_NumLeaves\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc33\">Correct</span>"
      ],
      "text/plain": [
       "Correct"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fill in the blank\n",
    "num_leaves = 7*7*7\n",
    "\n",
    "# Check your answer\n",
    "q_2.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a33691ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T04:16:39.576977Z",
     "iopub.status.busy": "2023-03-17T04:16:39.576561Z",
     "iopub.status.idle": "2023-03-17T04:16:39.581461Z",
     "shell.execute_reply": "2023-03-17T04:16:39.579966Z"
    },
    "papermill": {
     "duration": 0.015856,
     "end_time": "2023-03-17T04:16:39.584205",
     "exception": false,
     "start_time": "2023-03-17T04:16:39.568349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "# q_2.hint()\n",
    "# q_2.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43072ad6",
   "metadata": {
    "papermill": {
     "duration": 0.005726,
     "end_time": "2023-03-17T04:16:39.595637",
     "exception": false,
     "start_time": "2023-03-17T04:16:39.589911",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3) Which move will the agent select?\n",
    "\n",
    "In this question, you'll check your understanding of the minimax algorithm.  Remember that with this algorithm, \n",
    "> The agent chooses moves to get a score that is as high as possible, and it assumes the opponent will counteract this by choosing moves to force the score to be as low as possible.\n",
    "\n",
    "Consider the toy example below of a game tree that the agent will use to select its next move.  \n",
    "<center>\n",
    "<img src=\"https://i.imgur.com/QlfWGM9.png\" width=80%><br/>\n",
    "</center>\n",
    "\n",
    "Which move will the agent select?  Use your answer to set the value of the `selected_move` variable below.  Your answer should be one of `1`, `2`, or `3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4270bc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T04:16:39.608981Z",
     "iopub.status.busy": "2023-03-17T04:16:39.608592Z",
     "iopub.status.idle": "2023-03-17T04:16:39.619924Z",
     "shell.execute_reply": "2023-03-17T04:16:39.618615Z"
    },
    "papermill": {
     "duration": 0.021357,
     "end_time": "2023-03-17T04:16:39.622765",
     "exception": false,
     "start_time": "2023-03-17T04:16:39.601408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.2, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"3_WhichMove\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc33\">Correct</span>"
      ],
      "text/plain": [
       "Correct"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fill in the blank\n",
    "selected_move = 3\n",
    "\n",
    "# Check your answer\n",
    "q_3.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fdea144",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T04:16:39.638595Z",
     "iopub.status.busy": "2023-03-17T04:16:39.638182Z",
     "iopub.status.idle": "2023-03-17T04:16:39.643433Z",
     "shell.execute_reply": "2023-03-17T04:16:39.641751Z"
    },
    "papermill": {
     "duration": 0.017251,
     "end_time": "2023-03-17T04:16:39.645999",
     "exception": false,
     "start_time": "2023-03-17T04:16:39.628748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "# q_3.hint()\n",
    "# q_3.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c5ffd5",
   "metadata": {
    "papermill": {
     "duration": 0.005773,
     "end_time": "2023-03-17T04:16:39.658476",
     "exception": false,
     "start_time": "2023-03-17T04:16:39.652703",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 4) Examine the assumptions\n",
    "\n",
    "The minimax agent assumes that its opponent plays optimally (with respect to the heuristic, and using a game tree of limited depth).  But this is almost never the case, in practice: it's far more likely for the agent to encounter a suboptimal (that is: worse than optimal) opponent.  \n",
    "\n",
    "Say the minimax agent encounters a suboptimal opponent. Should we expect the minimax agent to still play the game well, despite the contradiction with its assumptions?  If so, why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ac24f05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T04:16:39.673308Z",
     "iopub.status.busy": "2023-03-17T04:16:39.672650Z",
     "iopub.status.idle": "2023-03-17T04:16:39.679472Z",
     "shell.execute_reply": "2023-03-17T04:16:39.677960Z"
    },
    "papermill": {
     "duration": 0.018254,
     "end_time": "2023-03-17T04:16:39.682566",
     "exception": false,
     "start_time": "2023-03-17T04:16:39.664312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# q_4.hint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44af8bb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T04:16:39.697454Z",
     "iopub.status.busy": "2023-03-17T04:16:39.696829Z",
     "iopub.status.idle": "2023-03-17T04:16:39.705956Z",
     "shell.execute_reply": "2023-03-17T04:16:39.704981Z"
    },
    "papermill": {
     "duration": 0.020487,
     "end_time": "2023-03-17T04:16:39.708955",
     "exception": false,
     "start_time": "2023-03-17T04:16:39.688468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 4, \"questionId\": \"4_Assumptions\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc99\">Solution:</span> We can still expect the minimax agent to perform well. On a high level, assuming an optimal opponent simply overestimates the opponent, but does not break the algorithm.  The effect of overestimating the opponent is merely that the minimax agent will take longer to win, than if it had a more accurate understanding of its opponent.  For instance, the minimax agent is highly unlikely to select the same column three times in its first three moves (since it assumes an optimal opponent that will certainly block the winning play in the next move), but this is not a bad initial strategy for playing against an agent that selects columns completely at random."
      ],
      "text/plain": [
       "Solution: We can still expect the minimax agent to perform well. On a high level, assuming an optimal opponent simply overestimates the opponent, but does not break the algorithm.  The effect of overestimating the opponent is merely that the minimax agent will take longer to win, than if it had a more accurate understanding of its opponent.  For instance, the minimax agent is highly unlikely to select the same column three times in its first three moves (since it assumes an optimal opponent that will certainly block the winning play in the next move), but this is not a bad initial strategy for playing against an agent that selects columns completely at random."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check your answer (Run this code cell to receive credit!)\n",
    "q_4.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704d6a69",
   "metadata": {
    "papermill": {
     "duration": 0.005794,
     "end_time": "2023-03-17T04:16:39.721870",
     "exception": false,
     "start_time": "2023-03-17T04:16:39.716076",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 5) Submit to the competition\n",
    "\n",
    "Now, it's time to submit an agent to the competition!  Use the next code cell to define an agent.  (You can see an example of how to write a valid agent in **[this notebook](https://www.kaggle.com/alexisbcook/create-a-connectx-agent)**.)\n",
    "\n",
    "If you decide to use the minimax code from the tutorial, you might like to add [**alpha-beta pruning**](https://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruning) to decrease the computation time (i.e., get the minimax algorithm to run much faster!).  In this case, \"alpha\" and \"beta\" to refer to two values that are maintained while the algorithm is running, that help to identify early stopping conditions.  \n",
    "\n",
    "Without alpha-beta pruning, minimax evaluates each leaf node.  With alpha-beta pruning, minimax only evaluates nodes that could provide information that affects the agent's choice of action.  Put another way, it identifies nodes that could not possibly affect the final result and avoids evaluating them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83e4fb29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T04:16:39.736806Z",
     "iopub.status.busy": "2023-03-17T04:16:39.736356Z",
     "iopub.status.idle": "2023-03-17T04:16:39.744305Z",
     "shell.execute_reply": "2023-03-17T04:16:39.742575Z"
    },
    "papermill": {
     "duration": 0.018987,
     "end_time": "2023-03-17T04:16:39.747060",
     "exception": false,
     "start_time": "2023-03-17T04:16:39.728073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def my_agent(obs, config):\n",
    "    # Your code here: Amend the agent!\n",
    "    import random\n",
    "    valid_moves = [col for col in range(config.columns) if obs.board[col] == 0]\n",
    "    for col in valid_moves:\n",
    "        if(check_winning_move(obs, config, col, obs.mark)): return col\n",
    "    for col in valid_moves:\n",
    "        if(check_winning_move(obs, config, col, obs.mark%2+1)): return col\n",
    "    return random.choice(valid_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "822418f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T04:16:39.762683Z",
     "iopub.status.busy": "2023-03-17T04:16:39.762253Z",
     "iopub.status.idle": "2023-03-17T04:16:39.771128Z",
     "shell.execute_reply": "2023-03-17T04:16:39.770089Z"
    },
    "papermill": {
     "duration": 0.019335,
     "end_time": "2023-03-17T04:16:39.773400",
     "exception": false,
     "start_time": "2023-03-17T04:16:39.754065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.2, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"5_JustSubmitEx3\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc33\">Thank you for creating an agent!</span>"
      ],
      "text/plain": [
       "Thank you for creating an agent!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this code cell to get credit for creating an agent\n",
    "q_5.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a4a334c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T04:16:39.788869Z",
     "iopub.status.busy": "2023-03-17T04:16:39.788475Z",
     "iopub.status.idle": "2023-03-17T04:16:39.796989Z",
     "shell.execute_reply": "2023-03-17T04:16:39.795413Z"
    },
    "papermill": {
     "duration": 0.019859,
     "end_time": "2023-03-17T04:16:39.800148",
     "exception": false,
     "start_time": "2023-03-17T04:16:39.780289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function my_agent at 0x7ff2196a0440> written to submission.py\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "import os\n",
    "\n",
    "def write_agent_to_file(function, file):\n",
    "    with open(file, \"a\" if os.path.exists(file) else \"w\") as f:\n",
    "        f.write(inspect.getsource(function))\n",
    "        print(function, \"written to\", file)\n",
    "\n",
    "write_agent_to_file(my_agent, \"submission.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f307ec",
   "metadata": {
    "papermill": {
     "duration": 0.006136,
     "end_time": "2023-03-17T04:16:39.812866",
     "exception": false,
     "start_time": "2023-03-17T04:16:39.806730",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Allen**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13.151769,
   "end_time": "2023-03-17T04:16:40.543201",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-17T04:16:27.391432",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
